{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's chunk Plato and Aristotle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from langchain_aws import BedrockLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List, Dict\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define your structured output model\n",
    "# class TransferNewsGrader(BaseModel):\n",
    "#     binary_score: str = Field(description=\"The article is about Magnus, 'yes' or 'no'\")\n",
    "\n",
    "# Load the configuration from the config.json file\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Set the state variables\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = config[\"AWS_ACCESS_KEY_ID\"]\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = config[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "\n",
    "# Usage\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "\n",
    "class SectionMetadata(BaseModel):\n",
    "    book_number: Optional[int] = Field(default=None, description=\"The number of the book in the series.\")\n",
    "    chapter_number: Optional[int] = Field(default=None, description=\"The number of the chapter.\")\n",
    "    section_number: Optional[int] = Field(default=None, description=\"The number of the section within the chapter.\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Optional[int]]:\n",
    "        \"\"\"\n",
    "        Convert the metadata to a dictionary format for easy access.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"book_number\": self.book_number,\n",
    "            \"chapter_number\": self.chapter_number,\n",
    "            \"section_number\": self.section_number\n",
    "        }\n",
    "\n",
    "class DocumentChunk(BaseModel):\n",
    "    text: str = Field(description=\"The extracted chunk of text.\")\n",
    "    metadata: SectionMetadata = Field(description=\"The metadata related to the text chunk.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulating an example chunk of text along with its metadata\n",
    "    text_chunk = \"This is an example text for chapter four.\"\n",
    "    \n",
    "    # Assume that the text chunk corresponds to Book 1, Chapter 4, Section 1\n",
    "    metadata = SectionMetadata(book_number=1, chapter_number=4, section_number=1)\n",
    "    document_chunk = DocumentChunk(text=text_chunk, metadata=metadata)\n",
    "\n",
    "    # Display the text and the associated metadata\n",
    "    print(document_chunk.text)\n",
    "    print(document_chunk.metadata.to_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bedrock_llm = BedrockLLM(\n",
    "    model_id=\"meta.llama3-70b-instruct-v1:0\",\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    ")\n",
    "\n",
    "# Create a prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=\"Give me the metadata for this chunk: {input}\"\n",
    ")\n",
    "\n",
    "# Create the LangChain LLM Chain\n",
    "transfer_news_chain = LLMChain(\n",
    "    llm=bedrock_llm,\n",
    "    prompt=prompt_template\n",
    ")\n",
    "\n",
    "# Use the chain\n",
    "input_text = \"  \"\n",
    "result = transfer_news_chain.run(input_text)\n",
    "\n",
    "# Assuming result is a string that corresponds to binary_score\n",
    "graded_result = MetaDataGrader(binary_score=result)\n",
    "print(graded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
